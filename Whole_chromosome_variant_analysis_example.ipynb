{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose data import checkpoint for your purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import raw data for chromosome of choice - vcf, gtf, CDS regions from gtf, unique gene IDs from gtf,\n",
    "#gene IDs that contain CDS regions (coding transcripts), UPIMAPI annotation file\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_chr1_vcf = pd.read_csv(\"./chr_vcf/chr1.gtf\", delimiter=\"\\t\", header=None)\n",
    "df_chr1_gtf = pd.read_csv(\"./chr_gtf/chr1.gtf\", delimiter=\"\\t\", header=None)\n",
    "df_chr1_gtf_CDS = pd.read_csv(\"./chr_gtf/CDSs/chr1.gtf\", delimiter=\"\\t\", header=None)\n",
    "df_chr1_names = pd.read_csv(\"./chr_gtf/uniq_CDS1.txt\", delimiter=\"\\t\", header=None)\n",
    "df_prot_coding_names = pd.read_csv(\"./coding_transcripts.txt\", delimiter=\"\\t\", header=None)\n",
    "upimapi_df = pd.read_csv(\"/home/Maxim/Bioinformatics/General_software/UPIMAPI/output/CambridgeChrs_adjusted/CambridgeChrs_adjusted/merged/Cambridge_UPIMAPI.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "#hard coded chromosomal length\n",
    "chromosome_length = 68399915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import intermediates\n",
    "SV_hits_test = pd.read_csv(\"./result/chr1.csv\")\n",
    "df_conserved = pd.read_csv(\"./conserved/conserved_transcripts_chr1.csv\")\n",
    "final1 = pd.read_csv(\"./result/processed/chr1.tsv\")\n",
    "SV_counts_df4 = pd.read_csv(\"./result/processed/counts/chr1.tsv\")\n",
    "\n",
    "overlap_df1 = pd.read_csv(\"./result/checkpoint_fin/overlaps/overlap_df_chr1.csv\")\n",
    "overlap_df1_CDS = pd.read_csv(\"./result/checkpoint_fin/overlaps/CDS/overlap_df_chr1.csv\")\n",
    "overlap_df1[\"Transcripts\"] = overlap_df1[\"Transcripts\"].fillna(\"[]\").apply(lambda x: eval(x))\n",
    "overlap_df1[\"Coords\"] = overlap_df1[\"Coords\"].fillna(\"[]\").apply(lambda x: eval(x))\n",
    "overlap_df1_CDS[\"Transcripts\"] = overlap_df1_CDS[\"Transcripts\"].fillna(\"[]\").apply(lambda x: eval(x))\n",
    "overlap_df1_CDS[\"Coords\"] = overlap_df1_CDS[\"Coords\"].fillna(\"[]\").apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary data for plotting chromosome browser images\n",
    "chromosome_length = 68399915\n",
    "all_SV_coords = pd.read_csv(\"./plotting/transcript_SV_coverage/checkpoint3/allSVchr1\")\n",
    "SV_coords = pd.read_csv(\"./plotting/transcript_SV_coverage/checkpoint3/overlapSVchr1\")\n",
    "tr_cov_df = pd.read_csv(\"./result/checkpoint_fin/overlaps/tr_cov_plot/tr_cov_df_chr1.csv\")\n",
    "overlap_norm_SV_coords2 = pd.read_csv(\"./plotting/transcript_SV_coverage/checkpoint3/NormSVLenPerTrChr1\")\n",
    "tr_cov_df_CDS = pd.read_csv(\"./result/checkpoint_fin/overlaps/CDS/tr_cov_plot/tr_cov_df_chr1.csv\")\n",
    "CDS_plot_SV_coords2 = pd.read_csv(\"./plotting/transcript_SV_coverage/checkpoint3/CDSSVchr1\")\n",
    "CDS_overlaps_test = pd.read_csv(\"./plotting/transcript_SV_coverage/checkpoint3/CDS_SV_densitychr1\")\n",
    "CDS_norm_SV_coords2 = pd.read_csv(\"./plotting/transcript_SV_coverage/checkpoint3/CDS_SV_densitychr1_coords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix raw data gene structures\n",
    "df_chr1_gtf.columns=['Chr', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'Attribute']\n",
    "df_chr1_gtf.insert(0, \"TrName\", df_chr1_names)\n",
    "\n",
    "df_chr1_gtf_CDS.columns=['Chr', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'Attribute']\n",
    "df_chr1_gtf_CDS.insert(0, \"TrName\", df_chr1_names)\n",
    "\n",
    "df_chr1_vcf.columns=['#CHROM', \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTERS\", \"INFO\", \"FORMAT\", \"UnnamedSample\"]\n",
    "\n",
    "qseqid_df = upimapi_df[\"qseqid\"].copy()\n",
    "upimapi_df.insert(0, \"TrName\", qseqid_df.str[:-2])\n",
    "test_df_upimapi = upimapi_df.astype(str).groupby(\"TrName\")[['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen',\n",
    "       'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore', 'Entry',\n",
    "       'Entry Name', 'Gene Names', 'Protein names', 'EC number',\n",
    "       'Function [CC]', 'Pathway', 'Keywords', 'Protein existence',\n",
    "       'Gene Ontology (GO)', 'Protein families', 'Taxonomic lineage',\n",
    "       'Taxonomic lineage (Ids)', 'Organism (ID)', 'BioCyc', 'BRENDA', 'CDD',\n",
    "       'eggNOG', 'Ensembl', 'InterPro', 'KEGG', 'Pfam', 'Reactome', 'RefSeq',\n",
    "       'UniPathway', 'Taxonomic lineage (SUPERKINGDOM)',\n",
    "       'Taxonomic lineage (PHYLUM)', 'Taxonomic lineage (CLASS)',\n",
    "       'Taxonomic lineage (ORDER)', 'Taxonomic lineage (FAMILY)',\n",
    "       'Taxonomic lineage (GENUS)', 'Taxonomic lineage (SPECIES)']].agg('! '.join).apply(lambda x: x[:].str.split('!')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out PASS, <30 QUAL, and non-homozygous from vcf\n",
    "print(df_chr1_vcf.value_counts(subset=\"FILTERS\"))\n",
    "df_chr1_vcf = df_chr1_vcf[df_chr1_vcf[\"FILTERS\"]==\"PASS\"]\n",
    "df_chr1_vcf = df_chr1_vcf[df_chr1_vcf[\"QUAL\"]>30]\n",
    "df_chr1_vcf = df_chr1_vcf[df_chr1_vcf[\"UnnamedSample\"].str.contains(\"1/1:\")]\n",
    "print(df_chr1_vcf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge gtf and vcf by coordinate overlaps\n",
    "SV_hits_test = pd.DataFrame()\n",
    "counter = 0 \n",
    "checkpoint = int(df_chr1_gtf.shape[0]/10)\n",
    "for index_gtf, row_gtf in df_chr1_gtf.iterrows():\n",
    "    counter += 1\n",
    "    if counter % checkpoint == 0:\n",
    "        SV_hits_test.to_csv(\"./result/chr1.csv\")\n",
    "        print(\"checkpoint: \", counter, \"/ \", df_chr1_gtf.shape[0])\n",
    "    vcf_df = df_chr1_vcf[(df_chr1_vcf[\"POS\"] >= row_gtf[4]) & (df_chr1_vcf[\"POS\"]<= row_gtf[5])]\n",
    "    if vcf_df.shape[0] > 0:\n",
    "        df_append = pd.concat([pd.DataFrame(row_gtf).transpose().reset_index(drop=True)]*vcf_df.shape[0])\n",
    "        combined = pd.concat([df_append.reset_index(drop=True), vcf_df.reset_index(drop=True)], axis = 1)\n",
    "        SV_hits_test = pd.concat([SV_hits_test, combined])\n",
    "SV_hits_test.columns = ['TrName', 'Chr', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'Attribute', '#CHROM', \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTERS\", \"INFO\", \"FORMAT\", \"UnnamedSample\"]\n",
    "SV_hits_test.to_csv(\"./result/chr1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate vcf/gtf coverage stats\n",
    "chromosome_length = 68399915\n",
    "non_coding_length = 68399915\n",
    "for index_gtf, row_gtf in df_chr1_gtf.iterrows():\n",
    "    non_coding_length = non_coding_length - (row_gtf[5]-row_gtf[4])\n",
    "coding_length = chromosome_length - non_coding_length\n",
    "coding_percentage = 100/chromosome_length*coding_length\n",
    "SV_mapped_percentage = 100/df_chr1_vcf.shape[0]*SV_hits_test.shape[0]\n",
    "print(\"Chromosome length: \", chromosome_length, \"\\nCoding length: \", coding_length, \n",
    "      \"\\nNon coding length: \", non_coding_length, \n",
    "      \"\\nCoding percentage: \", \"{:.2f}\".format(coding_percentage), \"%\",\n",
    "     \"\\nPercentage SVs mapped to coding regions: \", \"{:.2f}\".format(SV_mapped_percentage), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c29c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate SV properties\n",
    "SV_hits_test.reset_index(drop=True, inplace=True)\n",
    "SV_hits_test[\"REF_LEN\"] = SV_hits_test[\"REF\"].apply(len)\n",
    "SV_hits_test[\"ALT_LEN\"] = SV_hits_test[\"ALT\"].apply(len)\n",
    "SV_hits_test[\"MUT_LEN\"] = SV_hits_test[\"ALT_LEN\"]-SV_hits_test[\"REF_LEN\"]\n",
    "SV_hits_test[\"MUT_TYPE\"] = \"\"\n",
    "SV_hits_test[\"MUT_TYPE\"] = np.where(SV_hits_test[\"REF_LEN\"]==SV_hits_test[\"ALT_LEN\"], \"Substitution\", SV_hits_test[\"MUT_TYPE\"])\n",
    "SV_hits_test[\"MUT_TYPE\"] = np.where(SV_hits_test[\"REF_LEN\"]>SV_hits_test[\"ALT_LEN\"], \"Deletion\", SV_hits_test[\"MUT_TYPE\"])\n",
    "SV_hits_test[\"MUT_TYPE\"] = np.where(SV_hits_test[\"REF_LEN\"]<SV_hits_test[\"ALT_LEN\"], \"Insertion\", SV_hits_test[\"MUT_TYPE\"])\n",
    "SV_hits_test[\"SUB_TYPE\"] = \"\"\n",
    "SV_hits_test[\"SUB_TYPE\"] = np.where((SV_hits_test[\"REF\"]==\"A\") & (SV_hits_test[\"ALT\"]==\"G\") | (SV_hits_test[\"REF\"]==\"G\") & (SV_hits_test[\"ALT\"]==\"A\") | (SV_hits_test[\"REF\"]==\"C\") & (SV_hits_test[\"ALT\"]==\"T\") | (SV_hits_test[\"REF\"]==\"T\") & (SV_hits_test[\"ALT\"]==\"C\"), \"Transition\", SV_hits_test[\"SUB_TYPE\"])\n",
    "SV_hits_test[\"SUB_TYPE\"] = np.where((SV_hits_test[\"REF\"]==\"A\") & (SV_hits_test[\"ALT\"]==\"C\") | (SV_hits_test[\"REF\"]==\"C\") & (SV_hits_test[\"ALT\"]==\"A\") | (SV_hits_test[\"REF\"]==\"G\") & (SV_hits_test[\"ALT\"]==\"T\") | (SV_hits_test[\"REF\"]==\"T\") & (SV_hits_test[\"ALT\"]==\"G\") | (SV_hits_test[\"REF\"]==\"T\") & (SV_hits_test[\"ALT\"]==\"A\") | (SV_hits_test[\"REF\"]==\"A\") & (SV_hits_test[\"ALT\"]==\"T\") | (SV_hits_test[\"REF\"]==\"C\") & (SV_hits_test[\"ALT\"]==\"G\") | (SV_hits_test[\"REF\"]==\"G\") & (SV_hits_test[\"ALT\"]==\"C\"), \"Transversion\", SV_hits_test[\"SUB_TYPE\"])\n",
    "SV_hits_test[\"SUB_TYPE\"] = np.where((SV_hits_test[\"SUB_TYPE\"] == \"\") & (SV_hits_test[\"MUT_TYPE\"]==\"Substitution\"), \"Multi-substitution\", SV_hits_test[\"SUB_TYPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display SV property statistics \n",
    "print(\"Insertions :\", SV_hits_test[\"MUT_TYPE\"].value_counts()[\"Insertion\"], \n",
    "      \"\\nDeletions :\", SV_hits_test[\"MUT_TYPE\"].value_counts()[\"Deletion\"], \n",
    "      \"\\nSubstitutions :\", SV_hits_test[\"MUT_TYPE\"].value_counts()[\"Substitution\"], \n",
    "      \"\\nTransitions: \", SV_hits_test[\"SUB_TYPE\"].value_counts()[\"Transition\"], \n",
    "      \"\\nTransversions :\", SV_hits_test[\"SUB_TYPE\"].value_counts()[\"Transversion\"], \n",
    "      \"\\nMulti-substitutions\", 0)\n",
    "\n",
    "#no Multi-substitution SVs are found after filtering the vcf, hence it's commented out\n",
    "#SV_hits_test[\"SUB_TYPE\"].value_counts()[\"Multi-substitution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e15359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand the main dataframe with upimapi data and label CDS-containing transcripts\n",
    "final = SV_hits_test.merge(test_df_upimapi, on=[\"TrName\"], how=\"left\")\n",
    "df_prot_coding_names[\"Coding\"] = \"Yes\"\n",
    "df_prot_coding_names.columns=[\"TrName\",\"Coding\"]\n",
    "final1 = final.merge(df_prot_coding_names, on=[\"TrName\"], how=\"left\")\n",
    "final1.loc[final1[\"Coding\"]!=\"Yes\", \"Coding\"] = \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coding vs non-coding transcript stats\n",
    "protein_coding_length = 0\n",
    "for index_gtf, row_gtf in final1[final1[\"Coding\"]==\"Yes\"].drop_duplicates(subset=[\"TrName\"]).iterrows():\n",
    "    protein_coding_length = protein_coding_length + (row_gtf[5]-row_gtf[4])\n",
    "non_protein_coding_length = coding_length - protein_coding_length\n",
    "\n",
    "print(\"Protein-coding length: \", protein_coding_length, \"\\nProtein vs non-protein %: \",\n",
    "      \"{:.2f}\".format(100/coding_length*protein_coding_length), \"%\",\n",
    "      \"\\n% SVs found in protein-coding transcripts: \", \n",
    "      \"{:.2f}\".format(100/final1.shape[0]*final1[final1[\"Coding\"]==\"Yes\"].shape[0]), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9adc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find conserved/identical transcripts between CW and DP\n",
    "df_all = df_chr1_gtf.merge(final1.drop_duplicates(subset=[\"TrName\"]), on=[\"TrName\"], how=\"left\", indicator=True)\n",
    "df_conserved = df_all[df_all[\"_merge\"] == \"left_only\"]\n",
    "df_conserved.to_csv(\"./conserved/conserved_transcripts_chr1.csv\")\n",
    "print(\"Number of conserved transcripts:\", df_conserved.shape[0], \"/\", df_chr1_gtf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24acd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of SVs per transcript\n",
    "SV_counts_df = pd.DataFrame(final1[\"TrName\"].value_counts())\n",
    "SV_counts_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of SVs per transcript sorted by descending order\n",
    "SV_transcript_len = final1.groupby(\"TrName\")[['MUT_LEN']].sum().sort_values(by = [\"MUT_LEN\"], ascending = False ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ce9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of SVs per transcript sorted by descending SV frequency\n",
    "SV_counts_df1 = SV_counts_df.merge(SV_transcript_len, on=[\"TrName\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#absolute length of SVs per transcript sorted in descending order\n",
    "SV_transcript_len_abs = final1.groupby(\"TrName\")[['MUT_LEN']].apply(lambda c:c.abs().sum()).sort_values(by = [\"MUT_LEN\"], ascending = False ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#absolute length of SVs per transcript sorted by SV frequency\n",
    "SV_transcript_len_abs = final1.groupby(\"TrName\")[['MUT_LEN']].apply(lambda c:c.abs().sum()).sort_values(by = [\"MUT_LEN\"], ascending = False ).reset_index()\n",
    "SV_counts_df2 = SV_counts_df.merge(SV_transcript_len_abs, on=[\"TrName\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SV length to gene length ratio\n",
    "SV_transcript_len_abs = final1.groupby(\"TrName\")[['MUT_LEN']].apply(lambda c:c.abs().sum()).sort_values(by = [\"MUT_LEN\"], ascending = False ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a60016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute transcript length and normalise\n",
    "SV_counts_df1[\"Index\"] = SV_counts_df1.index\n",
    "\n",
    "final1[\"TrLength\"] = final1[\"End\"] - final1[\"Start\"]\n",
    "\n",
    "SV_counts_df3 = SV_counts_df2.merge(final1.drop_duplicates(subset=[\"TrName\"]), on=[\"TrName\"], how = \"left\")\n",
    "\n",
    "SV_counts_df3[\"#SV:MUT_LEN_abs\"] = SV_counts_df3[\"count\"]/SV_counts_df3[\"MUT_LEN_x\"]\n",
    "SV_counts_df3[\"#SV:TrLength\"] = SV_counts_df3[\"count\"]/SV_counts_df3[\"TrLength\"]\n",
    "SV_counts_df3_no_inf = SV_counts_df3.replace([np.inf, -np.inf], np.nan)\n",
    "SV_counts_df3[\"Index\"] = SV_counts_df3.index\n",
    "\n",
    "SV_counts_df4 = SV_counts_df3.merge(SV_counts_df1[[\"Index\",\"MUT_LEN\"]], on=\"Index\", how=\"left\", )\n",
    "\n",
    "SV_counts_df4[\"#MUT_LEN_total:TrLength\"] = SV_counts_df4[\"MUT_LEN\"]/SV_counts_df4[\"TrLength\"]\n",
    "SV_counts_df4[\"#MUT_LEN_abs:TrLength\"] = SV_counts_df4[\"MUT_LEN_x\"]/SV_counts_df4[\"TrLength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoints\n",
    "final1.to_csv(\"./result/checkpoint_fin/processed/chr1.tsv\")\n",
    "SV_counts_df4.to_csv(\"./result/checkpoint_fin/processed/counts/chr1.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8da4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT INCLUDED IN THESIS - GO ANNOTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2532a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat GO term histogram\n",
    "plt.rcParams['font.size'] = '16'\n",
    "GO_list = SV_counts_df4[\"Gene Ontology (GO)\"].explode()\n",
    "GO_list.dropna(inplace=True)\n",
    "GO_list = GO_list[GO_list != \"nan\"]\n",
    "GO_list = GO_list[GO_list != \" nan\"]\n",
    "GO_list = GO_list + \";\"\n",
    "GO_list = GO_list.str.split(pat = \";\")\n",
    "GO_list = GO_list.explode()\n",
    "GO_list = GO_list[GO_list != \"\"]\n",
    "vcounts = pd.DataFrame(GO_list.value_counts())\n",
    "vcounts.index.name = \"GO\"\n",
    "vcounts.reset_index(inplace=True)\n",
    "vcounts[\"GO\"] = vcounts[\"GO\"].str.strip()\n",
    "vcounts_df = vcounts.groupby([\"GO\"]).apply(lambda c:c.abs().sum()).sort_values(by = [\"count\"], ascending = False ).reset_index()\n",
    "fig, axes = plt.subplots(figsize=(15,20))\n",
    "vcounts_df.iloc[:50].plot(kind=\"barh\", x=\"GO\", y=\"count\", ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare GO sample list and save for processing using goatools\n",
    "GO_list.index.name = \"Index\"\n",
    "GO_list_df = GO_list.reset_index(inplace=False)\n",
    "GO_list_df[\"Gene Ontology (GO)\"] = GO_list_df[\"Gene Ontology (GO)\"].str.strip()\n",
    "GO_list_df1 = SV_counts_df4[\"TrName\"]\n",
    "GO_list_df1.index.name = \"Index\"\n",
    "GO_list_df1 = GO_list_df1.reset_index(inplace=False)\n",
    "GO_list_df2 = GO_list_df.merge(GO_list_df1, on=[\"Index\"], how=\"left\")\n",
    "GO_list_df3 = GO_list_df2[[\"TrName\", \"Gene Ontology (GO)\"]]\n",
    "\n",
    "GO_list_df3[\"TrName\"].to_csv(\"./GO/chr1_study.txt\", index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375bb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import goatools results - GO enrichment results - enriched gene groups in the chromosome (highly experimental)\n",
    "import re\n",
    "\n",
    "GO_enriched = pd.read_excel(\"./GO/chr_results/chr1.xlsx\")\n",
    "\n",
    "regex = []\n",
    "for values in GO_enriched[\"ratio_in_pop\"]:\n",
    "    regex.append(re.search(r'\\d+(?=\\/)', values).group())\n",
    "GO_enriched[\"pop_count\"] = regex\n",
    "GO_enriched[\"percent\"] = GO_enriched.study_count.astype(int) / GO_enriched.pop_count.astype(int)\n",
    "GO_enriched = GO_enriched.sort_values(by=\"p_fdr_bh\").reset_index(drop=True)\n",
    "GO_enriched[\"Index\"] = GO_enriched.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot enrichments\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(0.5, 3))\n",
    "\n",
    "cmap = mpl.cm.bwr_r\n",
    "#norm = mpl.colors.PowerNorm(vmin = GO_enriched.p_fdr_bh.min(),  vmax = GO_enriched.p_fdr_bh.max(), gamma = 0.5)\n",
    "norm = mpl.colors.Normalize(vmin = GO_enriched.p_fdr_bh.min(),  vmax = GO_enriched.p_fdr_bh.max())\n",
    "\n",
    "mapper = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "\n",
    "cbl = mpl.colorbar.ColorbarBase(ax, cmap = cmap, norm = norm, orientation = 'vertical')\n",
    "\n",
    "plt.figure(figsize = (15,200))\n",
    "\n",
    "ax = sns.barplot(data = GO_enriched, x = \"percent\", y = \"name\", palette = mapper.to_rgba(GO_enriched.p_fdr_bh.values), order = GO_enriched.sort_values(\"p_fdr_bh\").name)\n",
    "\n",
    "ax.set_yticklabels([textwrap.fill(e, 22) for e in GO_enriched[\"name\"]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of transcript overlap regions, CDS overlap regions, overlap region SV density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e15f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate overlaping transcript regions and prepare for plotting\n",
    "\n",
    "df_chr1_gtf.sort_values(by='Start', inplace=True)\n",
    "\n",
    "overlapping1 = []\n",
    "overlapping_coverage1 = []\n",
    "group_counter = 0\n",
    "i = 0\n",
    "\n",
    "while i < len(df_chr1_gtf):\n",
    "    start = df_chr1_gtf.iloc[i]['Start']\n",
    "    end = df_chr1_gtf.iloc[i]['End']\n",
    "    overlap_group = [i]\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    while i < len(df_chr1_gtf) and df_chr1_gtf.iloc[i]['Start'] <= end:\n",
    "        end = max(end, df_chr1_gtf.iloc[i]['End'])\n",
    "        overlap_group.append(i)\n",
    "        i += 1\n",
    "    \n",
    "    overlapping1.append(overlap_group)\n",
    "    overlapping_coverage1.append([start, end])\n",
    "\n",
    "overlap_df1 = pd.DataFrame({\n",
    "    'Transcripts': overlapping1,\n",
    "    'Coords': overlapping_coverage1,\n",
    "    'TrNum': range(len(overlapping1))\n",
    "})\n",
    "\n",
    "empty_regions = []\n",
    "for i in range(1, len(overlapping_coverage1)):\n",
    "    empty_regions.append([overlapping_coverage1[i - 1][1] + 1, overlapping_coverage1[i][0] - 1])\n",
    "\n",
    "empty_regions.append([0, overlapping_coverage1[0][0] - 1])\n",
    "empty_regions.append([overlapping_coverage1[-1][1] + 1, chromosome_length])\n",
    "\n",
    "dfdf1 = pd.DataFrame(empty_regions, columns=['Left', 'Right'])\n",
    "dfdf1['Coverage'] = 0\n",
    "dfdf3 = pd.concat([dfdf1[\"Left\"], dfdf1[\"Right\"]], axis = 0)\n",
    "dfdf3 = dfdf3.to_frame(name = \"Coords\")\n",
    "dfdf3[\"Coverage\"] = 0\n",
    "overlap_df1[\"Left\"] = [item[0] for item in overlap_df1[\"Coords\"].values]\n",
    "overlap_df1[\"Right\"] = [item[1] for item in overlap_df1[\"Coords\"].values]\n",
    "dfdf4 = pd.concat([overlap_df1[\"Left\"], overlap_df1[\"Right\"]], axis = 0)  \n",
    "dfdf4 = dfdf4.to_frame(name = \"Coords\")\n",
    "dfdf4[\"Coverage\"] = 1\n",
    "tr_cov_df = pd.concat([dfdf3, dfdf4], axis = 0)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import CDS gtf\n",
    "df_chr1_gtf_CDS = pd.read_csv(\"./chr_gtf/CDSs/chr1.gtf\", delimiter=\"\\t\", header=None)\n",
    "df_chr1_gtf_CDS.columns=['Chr', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'Attribute']\n",
    "df_chr1_gtf_CDS.insert(0, \"TrName\", df_chr1_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate overlaping CDS regions and prepare for plotting\n",
    "\n",
    "df_chr1_gtf_CDS.sort_values(by='Start', inplace=True)\n",
    "\n",
    "overlapping1 = []\n",
    "overlapping_coverage1 = []\n",
    "group_counter = 0\n",
    "i = 0\n",
    "\n",
    "while i < len(df_chr1_gtf_CDS):\n",
    "    start = df_chr1_gtf_CDS.iloc[i]['Start']\n",
    "    end = df_chr1_gtf_CDS.iloc[i]['End']\n",
    "    overlap_group = [i]\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    while i < len(df_chr1_gtf_CDS) and df_chr1_gtf_CDS.iloc[i]['Start'] <= end:\n",
    "        end = max(end, df_chr1_gtf_CDS.iloc[i]['End'])\n",
    "        overlap_group.append(i)\n",
    "        i += 1\n",
    "    \n",
    "    overlapping1.append(overlap_group)\n",
    "    overlapping_coverage1.append([start, end])\n",
    "\n",
    "overlap_df1_CDS = pd.DataFrame({\n",
    "    'Transcripts': overlapping1,\n",
    "    'Coords': overlapping_coverage1,\n",
    "    'TrNum': range(len(overlapping1))\n",
    "})\n",
    "\n",
    "empty_regions = []\n",
    "for i in range(1, len(overlapping_coverage1)):\n",
    "    empty_regions.append([overlapping_coverage1[i - 1][1] + 1, overlapping_coverage1[i][0] - 1])\n",
    "\n",
    "empty_regions.append([0, overlapping_coverage1[0][0] - 1])\n",
    "empty_regions.append([overlapping_coverage1[-1][1] + 1, chromosome_length])\n",
    "\n",
    "dfdf1 = pd.DataFrame(empty_regions, columns=['Left', 'Right'])\n",
    "dfdf1['Coverage'] = 0\n",
    "dfdf3 = pd.concat([dfdf1[\"Left\"], dfdf1[\"Right\"]], axis = 0)\n",
    "dfdf3 = dfdf3.to_frame(name = \"Coords\")\n",
    "dfdf3[\"Coverage\"] = 0\n",
    "overlap_df1_CDS[\"Left\"] = [item[0] for item in overlap_df1_CDS[\"Coords\"].values]\n",
    "overlap_df1_CDS[\"Right\"] = [item[1] for item in overlap_df1_CDS[\"Coords\"].values]\n",
    "dfdf4 = pd.concat([overlap_df1_CDS[\"Left\"], overlap_df1_CDS[\"Right\"]], axis = 0)  \n",
    "dfdf4 = dfdf4.to_frame(name = \"Coords\")\n",
    "dfdf4[\"Coverage\"] = 1\n",
    "tr_cov_df_CDS = pd.concat([dfdf3, dfdf4], axis = 0)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVs DF\n",
    "pd.set_option('display.max_columns', None)\n",
    "SVs_df = final1.drop_duplicates(subset=[\"POS\"])\n",
    "SVs_df[\"abs_MUT_LEN\"] = SVs_df[\"MUT_LEN\"].abs()\n",
    "df_chr1_gtf[\"TrLen\"] = df_chr1_gtf[\"End\"] - df_chr1_gtf[\"Start\"] \n",
    "\n",
    "#SV coverage plot data - transcript only\n",
    "empty_regions = []\n",
    "empty_regions.append(0)\n",
    "empty_regions.append(chromosome_length)\n",
    "\n",
    "SVs_df_re = SVs_df.reset_index()\n",
    "\n",
    "for index, row in SVs_df_re.iterrows():\n",
    "    empty_regions.append(SVs_df_re[\"POS\"][index] -1)\n",
    "    empty_regions.append(SVs_df_re[\"POS\"][index] + 1)\n",
    "\n",
    "empty_regions = list(set(empty_regions))\n",
    "\n",
    "SV_coords = pd.DataFrame()\n",
    "SV_coords[\"Coords\"] = empty_regions\n",
    "SV_coords[\"abs_MUT_LEN\"] = 0\n",
    "SV_coords1 = pd.DataFrame()\n",
    "SV_coords1[\"Coords\"] = SVs_df_re[\"POS\"]\n",
    "SV_coords1[\"abs_MUT_LEN\"] = SVs_df_re[\"abs_MUT_LEN\"]\n",
    "SV_coords1[\"abs_MUT_LEN\"].replace(0, 1, inplace=True)\n",
    "SV_coords = SV_coords[SV_coords[\"Coords\"].isin(SV_coords[\"Coords\"])]\n",
    "SV_coords = pd.concat([SV_coords, SV_coords1], axis = 0)\n",
    "\n",
    "#SV coverage plot data - all SVs\n",
    "all_SVs_df = df_chr1_vcf.drop_duplicates(subset=[\"POS\"])\n",
    "all_SVs_df[\"REF_LEN\"] = all_SVs_df[\"REF\"].apply(len)\n",
    "all_SVs_df[\"ALT_LEN\"] = all_SVs_df[\"ALT\"].apply(len)\n",
    "all_SVs_df[\"MUT_LEN\"] = all_SVs_df[\"ALT_LEN\"]-all_SVs_df[\"REF_LEN\"]\n",
    "all_SVs_df[\"abs_MUT_LEN\"] = all_SVs_df[\"MUT_LEN\"].abs()\n",
    "\n",
    "empty_regions = []\n",
    "empty_regions.append(0)\n",
    "empty_regions.append(chromosome_length)\n",
    "\n",
    "all_SVs_df_re = all_SVs_df.reset_index()\n",
    "\n",
    "for index, row in all_SVs_df_re.iterrows():\n",
    "    empty_regions.append(all_SVs_df_re[\"POS\"][index] -1)\n",
    "    empty_regions.append(all_SVs_df_re[\"POS\"][index] + 1)\n",
    "\n",
    "empty_regions = list(set(empty_regions))\n",
    "\n",
    "all_SV_coords = pd.DataFrame()\n",
    "all_SV_coords[\"Coords\"] = empty_regions\n",
    "all_SV_coords[\"abs_MUT_LEN\"] = 0\n",
    "all_SV_coords1 = pd.DataFrame()\n",
    "all_SV_coords1[\"Coords\"] = all_SVs_df_re[\"POS\"]\n",
    "all_SV_coords1[\"abs_MUT_LEN\"] = all_SVs_df_re[\"abs_MUT_LEN\"]\n",
    "all_SV_coords1[\"abs_MUT_LEN\"].replace(0, 1, inplace=True)\n",
    "all_SV_coords = all_SV_coords[all_SV_coords[\"Coords\"].isin(all_SV_coords[\"Coords\"])]\n",
    "all_SV_coords = pd.concat([all_SV_coords, all_SV_coords1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlap length and overlap midpoint\n",
    "overlap_df1[\"Overlap_len\"] =  overlap_df1[\"Right\"] - overlap_df1[\"Left\"]\n",
    "overlap_df1[\"Midpoint_coord\"] =  ((overlap_df1[\"Right\"] + overlap_df1[\"Left\"])/2).astype(int)\n",
    "\n",
    "#index all protein-coding transcripts in context of all transcripts as ordered by starting coordinate\n",
    "df_chr1_gtf_sorted = df_chr1_gtf.sort_values(by=[\"Start\"])\n",
    "df_chr1_gtf_sorted = df_chr1_gtf_sorted.reset_index(drop=True)\n",
    "df_chr1_gtf_sorted[\"index1\"] = df_chr1_gtf_sorted.index\n",
    "all_transcripts_df = df_chr1_gtf_sorted[[\"TrName\", \"index1\"]]\n",
    "final1_overlaps = final1.merge(all_transcripts_df, on=[\"TrName\"], how=\"left\")\n",
    "\n",
    "#calculate absolute mutation length of all SVs in protein coding transcripts\n",
    "final1_overlaps = final1.merge(all_transcripts_df, on=[\"TrName\"], how=\"left\")\n",
    "final1_overlaps = final1_overlaps.sort_values(by=[\"Start\"])\n",
    "final1_overlaps = final1_overlaps.drop_duplicates(subset=[\"POS\"])\n",
    "final1_overlaps[\"abs_MUT_LEN_diff\"] = final1_overlaps[\"MUT_LEN\"].abs()\n",
    "final1_overlaps[\"abs_MUT_LEN\"] = final1_overlaps[\"abs_MUT_LEN_diff\"].abs() + 1\n",
    "final1_overlaps[\"MUT_LEN_fixed\"] = final1_overlaps[[\"REF_LEN\", \"ALT_LEN\"]].max(axis=1)\n",
    "\n",
    "#sum up absolute mutation lengths for each protein coding transcript\n",
    "SV_overlaps_len_abs = final1_overlaps.groupby(\"TrName\")[['MUT_LEN_fixed']].apply(lambda c:c.abs().sum()).reset_index()\n",
    "final1_overlaps1 = final1_overlaps.drop_duplicates(subset=[\"index1\"])\n",
    "SV_overlaps_len_abs2 =  final1_overlaps1.merge(SV_overlaps_len_abs, on=[\"TrName\"], how=\"left\")\n",
    "\n",
    "#merge protein coding transcript absolute mutation length data with transcript overlap coordinate data\n",
    "index1_to_mut_len = SV_overlaps_len_abs2.groupby('index1')['MUT_LEN_fixed_y'].sum().to_dict()\n",
    "\n",
    "def calculate_overlap_mut_len(row):\n",
    "    return sum(index1_to_mut_len.get(index, 0) for index in row['Transcripts'])\n",
    "\n",
    "overlap_df1['overlap_MUT_LEN'] = overlap_df1.apply(calculate_overlap_mut_len, axis=1)\n",
    "\n",
    "    \n",
    "#calculate normalised absolute mutation length per transcript (SV density)\n",
    "overlap_df1[\"norm_overlap_MUT_LEN\"] = overlap_df1[\"overlap_MUT_LEN\"]/overlap_df1[\"Overlap_len\"]\n",
    "\n",
    "#calculate flanking coordinates for plotting\n",
    "empty_regions = []\n",
    "empty_regions.append(0)\n",
    "empty_regions.append(chromosome_length)\n",
    "\n",
    "overlap_df1 = overlap_df1.reset_index()\n",
    "\n",
    "for index, row in overlap_df1.iterrows():\n",
    "    empty_regions.append(overlap_df1[\"Midpoint_coord\"][index] -1)\n",
    "    empty_regions.append(overlap_df1[\"Midpoint_coord\"][index] + 1)\n",
    "\n",
    "empty_regions = list(set(empty_regions))\n",
    "\n",
    "overlap_norm_SV_coords = pd.DataFrame()\n",
    "overlap_norm_SV_coords[\"Coords\"] = empty_regions\n",
    "overlap_norm_SV_coords[\"norm_overlap_MUT_LEN\"] = 0.0\n",
    "overlap_norm_SV_coords1 = pd.DataFrame()\n",
    "overlap_norm_SV_coords1[\"Coords\"] = overlap_df1[\"Midpoint_coord\"]\n",
    "overlap_norm_SV_coords1[\"norm_overlap_MUT_LEN\"] = overlap_df1[\"norm_overlap_MUT_LEN\"]\n",
    "overlap_norm_SV_coords2 = pd.concat([overlap_norm_SV_coords, overlap_norm_SV_coords1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8813292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CDS SV plotting\n",
    "SVs_for_CDSs = final1.drop_duplicates(subset=[\"POS\"])\n",
    "\n",
    "#need POS per CDS overlap and need SV density per CDS overlap\n",
    "intervals = pd.IntervalIndex.from_arrays(overlap_df1_CDS[\"Left\"], overlap_df1_CDS[\"Right\"], \"both\")\n",
    "SVs_in_CDSs = SVs_for_CDSs[intervals.get_indexer(SVs_for_CDSs.POS.values) != -1]\n",
    "SVs_in_CDSs.drop_duplicates(subset=\"POS\")\n",
    "\n",
    "SVs_per_CDS = pd.DataFrame()\n",
    "for index, row in overlap_df1_CDS.iterrows():\n",
    "    interval = [pd.Interval(overlap_df1_CDS[\"Left\"][index], overlap_df1_CDS[\"Right\"][index], \"both\")]\n",
    "    interval_index = pd.IntervalIndex(interval)\n",
    "    SVs_in_CDS = SVs_in_CDSs[interval_index.get_indexer(SVs_in_CDSs.POS.values) != -1]\n",
    "    SVs_in_CDS[\"CDS_start\"] = overlap_df1_CDS[\"Left\"][index]\n",
    "    SVs_in_CDS[\"CDS_end\"] = overlap_df1_CDS[\"Right\"][index]\n",
    "    SVs_per_CDS = pd.concat([SVs_per_CDS, SVs_in_CDS], axis = 0)\n",
    "    \n",
    "SVs_per_CDS[\"MUT_LEN_fixed\"] = SVs_per_CDS[[\"REF_LEN\", \"ALT_LEN\"]].max(axis=1)\n",
    "SVs_per_CDS_abs = SVs_per_CDS.groupby(\"CDS_start\")[['MUT_LEN_fixed']].apply(lambda c:c.abs().sum()).reset_index()\n",
    "SVs_per_CDS_abs = SVs_per_CDS_abs.rename(columns={\"MUT_LEN_fixed\":\"MUT_LEN_per_CDS\"})\n",
    "SVs_per_CDS =  SVs_per_CDS.merge(SVs_per_CDS_abs, on=[\"CDS_start\"], how=\"left\")\n",
    "SVs_per_CDS[\"CDS_overlap_len\"] =  SVs_per_CDS[\"CDS_end\"] - SVs_per_CDS[\"CDS_start\"]\n",
    "SVs_per_CDS[\"CDS_midpoint_coord\"] =  ((SVs_per_CDS[\"CDS_end\"] + SVs_per_CDS[\"CDS_start\"])/2).astype(int)\n",
    "SVs_per_CDS[\"norm_overlap_MUT_LEN\"] = SVs_per_CDS[\"MUT_LEN_per_CDS\"]/SVs_per_CDS[\"CDS_overlap_len\"]\n",
    "\n",
    "#calculate flanking coordinates for plotting norm CDS SV density\n",
    "CDS_overlaps = overlap_df1_CDS.copy()\n",
    "CDS_overlaps = CDS_overlaps.rename(columns={\"Left\":\"CDS_start\",\"Right\":\"CDS_end\"})\n",
    "CDS_overlaps_test = CDS_overlaps.merge(SVs_per_CDS.drop_duplicates(subset=[\"CDS_start\"]), on=[\"CDS_start\"], how=\"left\")\n",
    "\n",
    "empty_regions = []\n",
    "empty_regions.append(0)\n",
    "empty_regions.append(chromosome_length)\n",
    "\n",
    "CDS_overlaps_test1 = CDS_overlaps_test[[\"CDS_midpoint_coord\", \"norm_overlap_MUT_LEN\"]].dropna().sort_values(by=[\"CDS_midpoint_coord\"])\n",
    "CDS_overlaps_test1 = CDS_overlaps_test1.reset_index()\n",
    "\n",
    "for index, row in CDS_overlaps_test1.iterrows():\n",
    "    empty_regions.append(CDS_overlaps_test1[\"CDS_midpoint_coord\"][index] -1)\n",
    "    empty_regions.append(CDS_overlaps_test1[\"CDS_midpoint_coord\"][index] + 1)\n",
    "\n",
    "empty_regions = list(set(empty_regions))\n",
    "\n",
    "CDS_norm_SV_coords = pd.DataFrame()\n",
    "CDS_norm_SV_coords[\"Coords\"] = empty_regions\n",
    "CDS_norm_SV_coords[\"norm_overlap_MUT_LEN\"] = 0.0\n",
    "CDS_norm_SV_coords1 = pd.DataFrame()\n",
    "CDS_norm_SV_coords1[\"Coords\"] = CDS_overlaps_test1[\"CDS_midpoint_coord\"]\n",
    "CDS_norm_SV_coords1[\"norm_overlap_MUT_LEN\"] = CDS_overlaps_test1[\"norm_overlap_MUT_LEN\"]\n",
    "CDS_norm_SV_coords2 = pd.concat([CDS_norm_SV_coords, CDS_norm_SV_coords1], axis = 0)\n",
    "\n",
    "CDS_SV_coords = SVs_per_CDS[[\"POS\", \"MUT_LEN_fixed\"]]\n",
    "\n",
    "#calculate flanking coordinates for plotting SVs\n",
    "empty_regions = []\n",
    "empty_regions.append(0)\n",
    "empty_regions.append(chromosome_length)\n",
    "\n",
    "CDS_SV_coords = CDS_SV_coords.reset_index()\n",
    "\n",
    "for index, row in CDS_SV_coords.iterrows():\n",
    "    empty_regions.append(CDS_SV_coords[\"POS\"][index] -1)\n",
    "    empty_regions.append(CDS_SV_coords[\"POS\"][index] + 1)\n",
    "\n",
    "empty_regions = list(set(empty_regions))\n",
    "\n",
    "CDS_plot_SV_coords = pd.DataFrame()\n",
    "CDS_plot_SV_coords[\"Coords\"] = empty_regions\n",
    "CDS_plot_SV_coords[\"MUT_LEN_fixed\"] = 0\n",
    "CDS_plot_SV_coords1 = pd.DataFrame()\n",
    "CDS_plot_SV_coords1[\"Coords\"] = CDS_SV_coords[\"POS\"]\n",
    "CDS_plot_SV_coords1[\"MUT_LEN_fixed\"] = CDS_SV_coords[\"MUT_LEN_fixed\"]\n",
    "CDS_plot_SV_coords2 = pd.concat([CDS_plot_SV_coords, CDS_plot_SV_coords1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all\n",
    "overlap_df1.to_csv(\"./result/checkpoint_fin/overlaps/overlap_df_chr1.csv\", index=False)\n",
    "tr_cov_df.to_csv(\"./result/checkpoint_fin/overlaps/tr_cov_plot/tr_cov_df_chr1.csv\", index=False)\n",
    "overlap_df1_CDS.to_csv(\"./result/checkpoint_fin/overlaps/CDS/overlap_df_chr1.csv\", index=False)\n",
    "tr_cov_df_CDS.to_csv(\"./result/checkpoint_fin/overlaps/CDS/tr_cov_plot/tr_cov_df_chr1.csv\", index=False)\n",
    "\n",
    "all_SV_coords.to_csv(\"./plotting/transcript_SV_coverage/checkpoint3/allSVchr1\")\n",
    "SV_coords.to_csv(\"./plotting/transcript_SV_coverage/checkpoint3/overlapSVchr1\")\n",
    "overlap_norm_SV_coords2.to_csv(\"./plotting/transcript_SV_coverage/checkpoint3/NormSVLenPerTrChr1\")\n",
    "\n",
    "CDS_plot_SV_coords2.to_csv(\"./plotting/transcript_SV_coverage/checkpoint3/CDSSVchr1\")\n",
    "CDS_norm_SV_coords2.to_csv(\"./plotting/transcript_SV_coverage/checkpoint3/CDS_SV_densitychr1_coords\")\n",
    "CDS_overlaps_test.to_csv(\"./plotting/transcript_SV_coverage/checkpoint3/CDS_SV_densitychr1\")\n",
    "\n",
    "tr_cov_df_CDS.reset_index().to_csv(\"./result/checkpoint_fin/overlaps/CDS/tr_cov_plot/tr_cov_df_chr1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c173a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole chromosome Myriapoda plot\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, gridspec_kw={'height_ratios': [10, 1, 10]},\n",
    "                         sharex=True)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "all_SV_coords.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"abs_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(0, chromosome_length), ax = axes[0], color='b', linewidth=2)\n",
    "\n",
    "SV_coords.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"abs_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(0, chromosome_length), ax = axes[0], color='r', linewidth=2)\n",
    "\n",
    "CDS_plot_SV_coords2.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"MUT_LEN_fixed\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(0, chromosome_length), ax = axes[0], color='g', linewidth=2)\n",
    "\n",
    "tr_cov_df.sort_values(by=[\"Coords\"]).plot.area(x=\"Coords\", y= \"Coverage\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(0, chromosome_length), ax = axes[1], color='r',linewidth=0.2)\n",
    "\n",
    "overlap_norm_SV_coords2.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"norm_overlap_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(0, chromosome_length), ax = axes[2], color='r')\n",
    "\n",
    "fig.suptitle(\"SV distribution, transcript distribution, and SV density on chromosome 1\",fontsize=140)\n",
    "axes[0].set_ylabel(\"\", fontsize=120, labelpad=170)\n",
    "axes[1].set_ylabel(\"\", fontsize=120, labelpad=420)\n",
    "axes[2].set_ylabel(\"\", fontsize=120, labelpad=320)\n",
    "plt.xlabel('Position on chromosome (1 x $10^7$)', fontsize=120, labelpad=110)\n",
    "plt.xticks(fontsize=100)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=100, pad=50, width=8, size=45)\n",
    "axes[0].tick_params(axis='both', which='minor', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[1].tick_params(axis='both', which='minor', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=100, pad=50, width=8, size=45)\n",
    "axes[2].tick_params(axis='both', which='minor', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[0].get_xaxis().set_visible(True)\n",
    "axes[1].get_xaxis().set_visible(False)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(prune='lower'))\n",
    "axes[1].xaxis.offsetText.set_fontsize(0)\n",
    "axes[1].set_yticklabels([])\n",
    "# axes[1].set_yticks([0,1])\n",
    "# axes[1].set_yticklabels([\"Absent\", \"Present\"])\n",
    "axes[2].invert_yaxis()\n",
    "axes[0].grid(color = 'green', linestyle = '--', dashes=(13, 25), linewidth = 2, alpha=0.75)\n",
    "axes[2].grid(color = 'green', linestyle = '--', dashes=(13, 25), linewidth = 2, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727938d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Myriapoda plot of region around the Metallothionein gene on Dinas Powys L. rubellus chromosome 1\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, gridspec_kw={'height_ratios': [10, 1, 10]},\n",
    "                         sharex=True)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "all_SV_coords.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"abs_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ylim=(0, 31), color='b', ax = axes[0], linewidth=2)\n",
    "\n",
    "SV_coords.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"abs_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ylim=(0, 31), ax = axes[0], color='r', linewidth=2)\n",
    "\n",
    "CDS_plot_SV_coords2.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"MUT_LEN_fixed\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ax = axes[0], color='g', linewidth=2)\n",
    "\n",
    "tr_cov_df.sort_values(by=[\"Coords\"]).plot.area(x=\"Coords\", y= \"Coverage\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ax = axes[1], color='r',linewidth=0.2)\n",
    "\n",
    "tr_cov_df_CDS.sort_values(by=[\"Coords\"]).plot.area(x=\"Coords\", y= \"Coverage\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ax = axes[1], color='g',linewidth=0.2)\n",
    "\n",
    "overlap_norm_SV_coords2.sort_values(by=[\"Coords\"]).plot.line(x=\"Coords\", y= \"norm_overlap_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ylim=(0, 0.15), ax = axes[2], color='r')\n",
    "\n",
    "CDS_norm_SV_coords2.sort_values(by=[\"Coords\"]).plot.line(\n",
    "                        x=\"Coords\", y= \"norm_overlap_MUT_LEN\", figsize=(200,60), grid=True,\n",
    "                       xlabel=\"Transcript #\", ylabel=\"Normalised total transcript length differential\", \n",
    "                        legend=False, xlim=(30868202, 30876289), ax = axes[2], color='g')\n",
    "\n",
    "fig.suptitle(\"Full MT2 Transcript\",fontsize=140)\n",
    "axes[0].set_ylabel(\"\", fontsize=120, labelpad=170)\n",
    "axes[1].set_ylabel(\"\", fontsize=120, labelpad=420)\n",
    "axes[2].set_ylabel(\"\", fontsize=120, labelpad=320)\n",
    "plt.xlabel('Position on chromosome (1 x $10^6$)', fontsize=120, labelpad=110)\n",
    "plt.xticks(fontsize=100)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=100, pad=50, width=8, size=45)\n",
    "axes[0].tick_params(axis='both', which='minor', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[1].tick_params(axis='both', which='minor', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=100, pad=50, width=8, size=45)\n",
    "axes[2].tick_params(axis='both', which='minor', labelsize=100, pad=50, width=0, size=0)\n",
    "axes[0].get_xaxis().set_visible(True)\n",
    "axes[1].get_xaxis().set_visible(False)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(prune='lower'))\n",
    "axes[1].xaxis.offsetText.set_fontsize(0)\n",
    "axes[1].set_yticklabels([])\n",
    "# axes[1].set_yticks([0,1])\n",
    "# axes[1].set_yticklabels([\"Absent\", \"Present\"])\n",
    "axes[2].invert_yaxis()\n",
    "axes[0].grid(color = 'green', linestyle = '--', dashes=(13, 25), linewidth = 2, alpha=0.75)\n",
    "axes[2].grid(color = 'green', linestyle = '--', dashes=(13, 25), linewidth = 2, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further SV statistics\n",
    "all_SVs_df = df_chr1_vcf.drop_duplicates(subset=[\"POS\"])\n",
    "all_SVs_df[\"REF_LEN\"] = all_SVs_df[\"REF\"].apply(len)\n",
    "all_SVs_df[\"ALT_LEN\"] = all_SVs_df[\"ALT\"].apply(len)\n",
    "all_SVs_df[\"MUT_LEN\"] = all_SVs_df[\"ALT_LEN\"]-all_SVs_df[\"REF_LEN\"]\n",
    "all_SVs_df[\"abs_MUT_LEN\"] = all_SVs_df[\"MUT_LEN\"].abs()\n",
    "all_SVs_df[\"SV_LEN\"] = all_SVs_df[[\"REF_LEN\", \"ALT_LEN\"]].max(axis=1)\n",
    "\n",
    "print(\"Number of SVs on the chromosome: \", all_SVs_df.shape[0], \n",
    "      \"\\nAverage SV length: \", all_SVs_df[\"SV_LEN\"].mean(),\n",
    "      \"\\nSV density per chromosome: \", all_SVs_df[\" \"].sum()/chromosome_length,\n",
    "      \"\\nSV density per gene coding overlap: \", \n",
    "      overlap_df1[\"overlap_MUT_LEN\"].sum()/overlap_df1[\"Overlap_len\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dec674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display SV type statistics \n",
    "SV_types_df = SV_hits_test.drop_duplicates(subset=[\"POS\"])\n",
    "\n",
    "print(\"Insertions :\", SV_types_df[\"MUT_TYPE\"].value_counts()[\"Insertion\"], \n",
    "      \"\\nDeletions :\", SV_types_df[\"MUT_TYPE\"].value_counts()[\"Deletion\"], \n",
    "      \"\\nSubstitutions :\", SV_types_df[\"MUT_TYPE\"].value_counts()[\"Substitution\"], \n",
    "      \"\\nTransitions: \", SV_types_df[\"SUB_TYPE\"].value_counts()[\"Transition\"], \n",
    "      \"\\nTransversions :\", SV_types_df[\"SUB_TYPE\"].value_counts()[\"Transversion\"], \n",
    "      \"\\nMulti-substitutions\", 0)\n",
    "\n",
    "#SV_hits_test[\"SUB_TYPE\"].value_counts()[\"Multi-substitution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb21487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding vs non-coding based on transcript overlaps rather than raw gtf data\n",
    "SV_types_df = SV_hits_test.drop_duplicates(subset=[\"POS\"])\n",
    "\n",
    "chromosome_length = 68399915\n",
    "non_coding_length = 68399915\n",
    "\n",
    "for index_gtf, row_gtf in overlap_df1.iterrows():\n",
    "    non_coding_length = non_coding_length - (row_gtf[5]-row_gtf[4])\n",
    "coding_length = chromosome_length - non_coding_length\n",
    "coding_percentage = 100/chromosome_length*coding_length\n",
    "SV_mapped_percentage = 100/df_chr1_vcf.shape[0]*SV_types_df.shape[0]\n",
    "print(\"Chromosome length: \", chromosome_length, \"\\nCoding length: \", coding_length, \n",
    "      \"\\nNon coding length: \", non_coding_length, \n",
    "      \"\\nCoding percentage: \", \"{:.2f}\".format(coding_percentage), \"%\",\n",
    "     \"\\nPercentage SVs mapped to coding regions: \", \"{:.2f}\".format(SV_mapped_percentage), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05c15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
